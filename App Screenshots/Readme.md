# Application Screenshots
Screenshots from the functionalities of the framework in use for the proof-of-concept application.

---

## Application Home
### Home page for the proof-of-concept application.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/start.PNG" width="600">
</p>

---

## Application Enrollment
### Enrollment process, snapshots per rotation at each wall.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/enroll_complete.PNG" width="600">
</p>

---

## Scene Descriptions for each Wall
### A scene decription for each wall in the room graph. Once approved, the graph can be created though "Save" button.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/enroll_scenes.PNG" width="600">
</p>

---

## Scene Description
### Scene decription detail view for a created vertex in the room graph.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/scene_detail.PNG" width="600">
</p>

---

## Floormap Graphs
### Floormap Graph Linking View (Manual Process).
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/linking.PNG" width="600">
</p>
<p>Notice that the compass-based heuristic have some differences between rooms in certain instances. This is because, based on the magnetic heading, the angle can be only a few degrees short of the next; In this case, "Southwest" and "West" were extremley close together in heading angles.</p>

---

## Room Detection
### Using TinyViT and image similarity within the graph to detect rooms.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/room_detection.PNG" width="600">
</p>

---

## Basic Question to LLM
### Using head motion (right) to query the LLM what the proximal environment to the right is.
<p align="center">
  <img src="https://github.com/anonymousresearcher62-maker/Motion-Intent-Source-Code/blob/main/App%20Screenshots/inference.PNG" width="600">
</p>

---
